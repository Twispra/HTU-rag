# -*- coding: utf-8 -*-
"""
æ™ºèƒ½æ–‡æ¡£åˆ†å—å·¥å…·ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
- åŸºäºè¯­ä¹‰è¾¹ç•Œçš„æ™ºèƒ½åˆ‡åˆ†
- æ”¯æŒMarkdownç»“æ„æ„ŸçŸ¥ï¼ˆæ ‡é¢˜ã€åˆ—è¡¨ã€è¡¨æ ¼ï¼‰
- è‡ªé€‚åº”å—å¤§å°ä¼˜åŒ–
- ä¿ç•™æ–‡æ¡£ç»“æ„ä¿¡æ¯
"""
import os, re, json, pathlib
from tqdm import tqdm
from typing import List, Tuple, Dict
import argparse

# ç›®å½•é…ç½®
DATABASE_DIR = "../../dataset/database"
CHUNK_DIR = "../../dataset/chunks"
os.makedirs(CHUNK_DIR, exist_ok=True)


class SmartChunker:
    """æ™ºèƒ½æ–‡æ¡£åˆ†å—å™¨"""

    def __init__(self, target_size: int = 600, min_size: int = 50,
                 max_size: int = 1200, overlap: int = 120):
        """
        åˆå§‹åŒ–åˆ†å—å™¨ï¼ˆä¼˜åŒ–ç‰ˆï¼šå¢å¤§å—å¤§å°ä»¥ä¿ç•™æ›´å¤šä¸Šä¸‹æ–‡ï¼‰

        Args:
            target_size: ç›®æ ‡å—å¤§å°ï¼ˆå­—ç¬¦æ•°ï¼‰- å¢åŠ åˆ°600ä»¥ä¿ç•™æ›´å®Œæ•´çš„ä¿¡æ¯
            min_size: æœ€å°å—å¤§å°
            max_size: æœ€å¤§å—å¤§å° - å¢åŠ åˆ°1200ä»¥é¿å…æˆªæ–­é‡è¦å†…å®¹
            overlap: å—ä¹‹é—´çš„é‡å å­—ç¬¦æ•° - å¢åŠ åˆ°120ä»¥ä¿æŒè¿è´¯æ€§
        """
        self.target_size = target_size
        self.min_size = min_size
        self.max_size = max_size
        self.overlap = overlap

        # å¥å­è¾¹ç•Œæ­£åˆ™ï¼ˆåŒ…å«æ›´å¤šåˆ†éš”ç¬¦ï¼‰
        self.sent_pattern = re.compile(r'(?<=[ã€‚ï¼ï¼Ÿ!?ï¼›;\n])\s*')

    def extract_structure(self, text: str) -> List[Dict]:
        """
        æå–Markdownæ–‡æ¡£ç»“æ„

        Returns:
            ç»“æ„åŒ–çš„æ–‡æœ¬æ®µè½åˆ—è¡¨ï¼ŒåŒ…å«æ®µè½ç±»å‹å’Œå†…å®¹
        """
        lines = text.split('\n')
        sections = []
        current_section = {'type': 'text', 'content': [], 'level': 0}
        in_table = False
        in_list = False

        for line in lines:
            stripped = line.strip()

            # è·³è¿‡å…ƒä¿¡æ¯åˆ†éš”ç¬¦å’Œå…ƒä¿¡æ¯è¡Œ
            if stripped == '---':
                continue
            if stripped.startswith('**') and ('æ¥æº' in stripped or 'å‘å¸ƒæ—¥æœŸ' in stripped):
                continue

            # æ ‡é¢˜æ£€æµ‹
            if stripped.startswith('#'):
                if current_section['content']:
                    sections.append(current_section)
                level = len(re.match(r'^#+', stripped).group())
                heading_text = stripped.lstrip('#').strip()  # ç§»é™¤#å·ï¼Œåªä¿ç•™æ ‡é¢˜æ–‡æœ¬
                current_section = {
                    'type': 'heading',
                    'level': level,
                    'content': [heading_text]
                }
                sections.append(current_section)
                current_section = {'type': 'text', 'content': [], 'level': level}
                continue

            # è¡¨æ ¼æ£€æµ‹
            if '|' in stripped and stripped.count('|') >= 2:
                if not in_table:
                    if current_section['content']:
                        sections.append(current_section)
                    current_section = {'type': 'table', 'content': [], 'level': current_section['level']}
                    in_table = True
                current_section['content'].append(line)
                continue
            elif in_table:
                sections.append(current_section)
                current_section = {'type': 'text', 'content': [], 'level': current_section['level']}
                in_table = False

            # åˆ—è¡¨æ£€æµ‹
            if re.match(r'^[\d\-*â€¢]+[.)]\s+', stripped) or re.match(r'^[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+[ã€.]\s+', stripped):
                if not in_list:
                    if current_section['content'] and current_section['type'] != 'list':
                        sections.append(current_section)
                        current_section = {'type': 'list', 'content': [], 'level': current_section['level']}
                    elif not current_section['content']:
                        current_section['type'] = 'list'
                    in_list = True
                current_section['content'].append(line)
                continue
            elif in_list and stripped:
                # åˆ—è¡¨é¡¹å»¶ç»­
                current_section['content'].append(line)
                continue
            elif in_list and not stripped:
                sections.append(current_section)
                current_section = {'type': 'text', 'content': [], 'level': current_section['level']}
                in_list = False
                continue

            # æ™®é€šæ–‡æœ¬
            if stripped:
                if current_section['type'] not in ['text']:
                    if current_section['content']:
                        sections.append(current_section)
                    current_section = {'type': 'text', 'content': [], 'level': current_section['level']}
                current_section['content'].append(line)
            else:
                # ç©ºè¡Œä½œä¸ºæ®µè½åˆ†éš”
                if current_section['content']:
                    sections.append(current_section)
                    current_section = {'type': 'text', 'content': [], 'level': current_section['level']}

        # æ·»åŠ æœ€åä¸€ä¸ªsection
        if current_section['content']:
            sections.append(current_section)

        return sections

    def chunk_section(self, section: Dict) -> List[str]:
        """
        å¯¹å•ä¸ªsectionè¿›è¡Œåˆ†å—

        Args:
            section: åŒ…å«typeã€contentã€levelçš„å­—å…¸

        Returns:
            åˆ†å—åçš„æ–‡æœ¬åˆ—è¡¨
        """
        content = '\n'.join(section['content']).strip()
        if not content:
            return []

        # è¡¨æ ¼å’Œåˆ—è¡¨å°½é‡ä¿æŒå®Œæ•´
        if section['type'] in ['table', 'list']:
            if len(content) <= self.max_size:
                return [content]
            # å¦‚æœè¿‡é•¿ï¼ŒæŒ‰è¡Œæ‹†åˆ†
            lines = section['content']
            chunks = []
            current = []
            current_len = 0
            for line in lines:
                line_len = len(line)
                if current_len + line_len > self.target_size and current:
                    chunks.append('\n'.join(current))
                    current = [line]
                    current_len = line_len
                else:
                    current.append(line)
                    current_len += line_len
            if current:
                chunks.append('\n'.join(current))
            return chunks

        # æ ‡é¢˜å•ç‹¬æˆå—ï¼ˆä¸åç»­æ–‡æœ¬åˆå¹¶ï¼‰
        if section['type'] == 'heading':
            return [content]

        # æ™®é€šæ–‡æœ¬ï¼šåŸºäºå¥å­è¾¹ç•Œåˆ†å—
        return self._chunk_text_by_sentences(content)

    def _chunk_text_by_sentences(self, text: str) -> List[str]:
        """
        åŸºäºå¥å­è¾¹ç•Œå¯¹æ–‡æœ¬è¿›è¡Œåˆ†å—
        """
        # åˆ†å¥
        sentences = self.sent_pattern.split(text)
        sentences = [s.strip() for s in sentences if s.strip()]

        if not sentences:
            return []

        chunks = []
        current_chunk = []
        current_len = 0

        for sent in sentences:
            sent_len = len(sent)

            # å•å¥è¿‡é•¿ï¼Œå¼ºåˆ¶æˆªæ–­
            if sent_len > self.max_size:
                if current_chunk:
                    chunks.append(''.join(current_chunk))
                    current_chunk = []
                    current_len = 0
                # æŒ‰æœ€å¤§é•¿åº¦æˆªæ–­
                for i in range(0, sent_len, self.target_size):
                    chunks.append(sent[i:i+self.target_size])
                continue

            # åˆ¤æ–­æ˜¯å¦éœ€è¦æ–°å»ºå—
            if current_len + sent_len > self.target_size and current_chunk:
                chunk_text = ''.join(current_chunk)
                chunks.append(chunk_text)

                # æ·»åŠ é‡å éƒ¨åˆ†
                overlap_text = chunk_text[-self.overlap:] if len(chunk_text) > self.overlap else chunk_text
                current_chunk = [overlap_text, sent]
                current_len = len(overlap_text) + sent_len
            else:
                current_chunk.append(sent)
                current_len += sent_len

        # æ·»åŠ æœ€åä¸€ä¸ªå—
        if current_chunk:
            chunks.append(''.join(current_chunk))

        # è¿‡æ»¤è¿‡çŸ­çš„å—
        return [c for c in chunks if len(c) >= self.min_size]

    def chunk_document(self, text: str, title: str = "") -> List[Tuple[str, Dict]]:
        """
        å¯¹æ•´ä¸ªæ–‡æ¡£è¿›è¡Œæ™ºèƒ½åˆ†å—

        Args:
            text: æ–‡æ¡£å†…å®¹ï¼ˆMarkdownæ ¼å¼ï¼‰
            title: æ–‡æ¡£æ ‡é¢˜

        Returns:
            (å—æ–‡æœ¬, å—å…ƒæ•°æ®) çš„åˆ—è¡¨
        """
        sections = self.extract_structure(text)
        chunks_with_meta = []
        current_heading = title
        heading_stack = [title]  # æ ‡é¢˜å±‚çº§æ ˆ

        # åˆå¹¶è¿ç»­çš„æ–‡æœ¬sectionsä»¥é¿å…è¿‡åº¦ç¢ç‰‡åŒ–
        merged_sections = []
        i = 0
        while i < len(sections):
            section = sections[i]

            if section['type'] == 'text':
                # åˆå¹¶è¿ç»­çš„æ–‡æœ¬sections
                merged_content = []
                current_level = section['level']

                while i < len(sections) and sections[i]['type'] == 'text' and sections[i]['level'] == current_level:
                    merged_content.extend(sections[i]['content'])
                    i += 1

                merged_sections.append({
                    'type': 'text',
                    'content': merged_content,
                    'level': current_level
                })
            else:
                merged_sections.append(section)
                i += 1

        # ç°åœ¨å¤„ç†åˆå¹¶åçš„sections
        for section in merged_sections:
            # æ›´æ–°æ ‡é¢˜ä¸Šä¸‹æ–‡
            if section['type'] == 'heading':
                heading_text = section['content'][0] if section['content'] else ""
                level = section['level']

                # ç»´æŠ¤æ ‡é¢˜æ ˆ
                while len(heading_stack) > level:
                    heading_stack.pop()
                if len(heading_stack) == level:
                    heading_stack[-1] = heading_text
                else:
                    heading_stack.append(heading_text)

                current_heading = ' > '.join(heading_stack)

                # æ ‡é¢˜ä¹Ÿä½œä¸ºç‹¬ç«‹chunkï¼ˆä¾¿äºæ£€ç´¢ï¼‰
                chunks_with_meta.append((
                    heading_text,
                    {'type': 'heading', 'heading': current_heading, 'level': level}
                ))
                continue

            # å¯¹sectionå†…å®¹åˆ†å—
            section_chunks = self.chunk_section(section)
            for chunk_text in section_chunks:
                chunks_with_meta.append((
                    chunk_text,
                    {'type': section['type'], 'heading': current_heading}
                ))

        return chunks_with_meta


def process_documents(database_dir: str = DATABASE_DIR,
                     chunk_dir: str = CHUNK_DIR,
                     target_size: int = 600,
                     overlap: int = 120):
    """
    æ‰¹é‡å¤„ç†æ–‡æ¡£ç›®å½•ï¼ˆä¼˜åŒ–ç‰ˆï¼šæ›´å¤§çš„å—å¤§å°ï¼‰

    Args:
        database_dir: æ•°æ®åº“ç›®å½•ï¼ˆåŒ…å«å„ä¸ªæ–‡æ¡£æ–‡ä»¶å¤¹ï¼‰
        chunk_dir: è¾“å‡ºåˆ†å—ç›®å½•
        target_size: ç›®æ ‡å—å¤§å°ï¼ˆå¢åŠ åˆ°600ï¼‰
        overlap: é‡å å¤§å°ï¼ˆå¢åŠ åˆ°120ï¼‰
    """
    chunker = SmartChunker(target_size=target_size, overlap=overlap)
    database_path = pathlib.Path(database_dir)

    if not database_path.exists():
        print(f"âŒ æ•°æ®åº“ç›®å½•ä¸å­˜åœ¨: {database_dir}")
        return

    doc_dirs = [d for d in database_path.iterdir() if d.is_dir()]
    print(f"ğŸ“‚ å‘ç° {len(doc_dirs)} ä¸ªæ–‡æ¡£ç›®å½•")

    total_chunks = 0
    processed_docs = 0

    for doc_dir in tqdm(doc_dirs, desc="ğŸ”„ Processing documents"):
        meta_path = doc_dir / "meta.json"
        content_path = doc_dir / "content.md"

        if not meta_path.exists() or not content_path.exists():
            continue

        # è¯»å–å…ƒæ•°æ®å’Œå†…å®¹
        try:
            meta = json.loads(meta_path.read_text(encoding="utf-8"))
            text = content_path.read_text(encoding="utf-8")
        except Exception as e:
            print(f"âš ï¸  è¯»å–å¤±è´¥ {doc_dir.name}: {e}")
            continue

        title = meta.get("title", "æ— æ ‡é¢˜é€šçŸ¥")
        doc_id = meta["doc_id"]

        # æ™ºèƒ½åˆ†å—
        chunks_with_meta = chunker.chunk_document(text, title)

        if not chunks_with_meta:
            continue

        # ä¿å­˜åˆ†å—ç»“æœ
        out_path = pathlib.Path(chunk_dir) / f"{doc_id}.jsonl"
        with open(out_path, "w", encoding="utf-8") as f:
            for i, (chunk_text, chunk_meta) in enumerate(chunks_with_meta, 1):
                item = {
                    "id": f"{doc_id}#p{i}",
                    "doc_id": doc_id,
                    "titles": [title, chunk_meta.get('heading', title)],
                    "text": chunk_text,
                    "chunk_type": chunk_meta.get('type', 'text'),
                    "heading_path": chunk_meta.get('heading', title),
                    "doc_type": meta.get("doc_type", "é€šçŸ¥å…¬å‘Š"),
                    "dept": meta.get("dept", "æ•™åŠ¡å¤„"),
                    "publish_date": meta.get("publish_date"),
                    "source_url": meta.get("source_url"),
                    "has_attachments": meta.get("has_attachments", False),
                    "attachment_count": meta.get("attachment_count", 0),
                    "lang": "zh"
                }
                f.write(json.dumps(item, ensure_ascii=False) + "\n")

        total_chunks += len(chunks_with_meta)
        processed_docs += 1

    print(f"\nâœ… åˆ†å—å®Œæˆ!")
    print(f"   - å¤„ç†æ–‡æ¡£: {processed_docs} ä¸ª")
    print(f"   - ç”Ÿæˆå—: {total_chunks} ä¸ª")
    print(f"   - å¹³å‡æ¯æ–‡æ¡£: {total_chunks/processed_docs:.1f} ä¸ªå—" if processed_docs > 0 else "")
    print(f"   - è¾“å‡ºç›®å½•: {chunk_dir}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="æ™ºèƒ½æ–‡æ¡£åˆ†å—å·¥å…·")
    parser.add_argument("--database-dir", default=DATABASE_DIR, help="æ•°æ®åº“ç›®å½•")
    parser.add_argument("--chunk-dir", default=CHUNK_DIR, help="åˆ†å—è¾“å‡ºç›®å½•")
    parser.add_argument("--target-size", type=int, default=600, help="ç›®æ ‡å—å¤§å°ï¼ˆä¼˜åŒ–ä¸º600ï¼‰")
    parser.add_argument("--overlap", type=int, default=120, help="å—é‡å å¤§å°ï¼ˆä¼˜åŒ–ä¸º120ï¼‰")

    args = parser.parse_args()

    process_documents(
        database_dir=args.database_dir,
        chunk_dir=args.chunk_dir,
        target_size=args.target_size,
        overlap=args.overlap
    )

