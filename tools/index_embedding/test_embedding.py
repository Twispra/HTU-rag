# -*- coding: utf-8 -*-
"""
Embedding æ¨¡å‹å¯¹æ¯”æµ‹è¯•

æµ‹è¯•ä¸åŒæ¨¡å‹çš„ï¼š
1. å‘é‡ç»´åº¦
2. åŠ è½½æ—¶é—´
3. ç¼–ç é€Ÿåº¦
4. è¯­ä¹‰ç›¸ä¼¼åº¦è´¨é‡
"""
import time
import numpy as np
from sentence_transformers import SentenceTransformer


def test_embedding_model(model_name: str):
    """æµ‹è¯•embeddingæ¨¡å‹æ€§èƒ½"""
    print(f"\n{'='*70}")
    print(f"æµ‹è¯•æ¨¡å‹: {model_name}")
    print(f"{'='*70}")

    # 1. åŠ è½½æ¨¡å‹
    print("\n1. åŠ è½½æ¨¡å‹...")
    start = time.time()
    try:
        model = SentenceTransformer(model_name)
        load_time = time.time() - start
        print(f"   âœ… åŠ è½½æˆåŠŸ")
        print(f"   â±ï¸  åŠ è½½æ—¶é—´: {load_time:.2f}ç§’")
    except Exception as e:
        print(f"   âŒ åŠ è½½å¤±è´¥: {e}")
        return None

    # 2. æ¨¡å‹ä¿¡æ¯
    print(f"\n2. æ¨¡å‹ä¿¡æ¯:")
    print(f"   å‘é‡ç»´åº¦: {model.get_sentence_embedding_dimension()}")
    print(f"   æœ€å¤§åºåˆ—é•¿åº¦: {model.max_seq_length}")

    # 3. ç¼–ç é€Ÿåº¦æµ‹è¯•
    print(f"\n3. ç¼–ç é€Ÿåº¦æµ‹è¯•:")
    test_texts = [
        "å…³äºå¼€å±•2026å±Šæ¯•ä¸šç”Ÿæ¯•ä¸šå›¾åƒä¿¡æ¯é‡‡é›†çš„é€šçŸ¥",
        "æ²³å—å¸ˆèŒƒå¤§å­¦å…³äº2023çº§æœ¬ç§‘ç”ŸæŠ¥åå‚åŠ æ™®é€šè¯æ°´å¹³æµ‹è¯•çš„é€šçŸ¥",
        "å…³äºä¸¾åŠæ•™å¸ˆæ•™å­¦åˆ›æ–°å¤§èµ›å¤‡èµ›æŒ‡å¯¼åŸ¹è®­çš„é€šçŸ¥"
    ]

    start = time.time()
    embeddings = model.encode(test_texts, normalize_embeddings=True)
    encode_time = time.time() - start

    print(f"   ç¼–ç 3ä¸ªæ–‡æœ¬ç”¨æ—¶: {encode_time*1000:.1f}ms")
    print(f"   å¹³å‡æ¯ä¸ª: {encode_time*1000/len(test_texts):.1f}ms")

    # 4. è¯­ä¹‰ç›¸ä¼¼åº¦æµ‹è¯•
    print(f"\n4. è¯­ä¹‰ç›¸ä¼¼åº¦æµ‹è¯•:")
    query = "æ¯•ä¸šå›¾åƒé‡‡é›†"
    docs = [
        "å…³äºå¼€å±•2026å±Šæ¯•ä¸šç”Ÿæ¯•ä¸šå›¾åƒä¿¡æ¯é‡‡é›†çš„é€šçŸ¥",  # é«˜ç›¸å…³
        "å…³äºä¸¾åŠæ•™å¸ˆæ•™å­¦åˆ›æ–°å¤§èµ›çš„é€šçŸ¥",  # ä½ç›¸å…³
        "2026å±Šæ¯•ä¸šç”Ÿç…§ç‰‡æ‹æ‘„å®‰æ’é€šçŸ¥"  # ä¸­ç›¸å…³
    ]

    q_emb = model.encode([query], normalize_embeddings=True)[0]
    d_embs = model.encode(docs, normalize_embeddings=True)

    similarities = [np.dot(q_emb, d_emb) for d_emb in d_embs]

    print(f"   æŸ¥è¯¢: '{query}'")
    for i, (doc, sim) in enumerate(zip(docs, similarities), 1):
        print(f"   [{i}] ç›¸ä¼¼åº¦={sim:.4f}: {doc[:40]}...")

    # 5. åŒºåˆ†åº¦æµ‹è¯•
    print(f"\n5. åŒºåˆ†åº¦åˆ†æ:")
    print(f"   æœ€é«˜ç›¸ä¼¼åº¦: {max(similarities):.4f}")
    print(f"   æœ€ä½ç›¸ä¼¼åº¦: {min(similarities):.4f}")
    print(f"   åŒºåˆ†åº¦: {max(similarities) - min(similarities):.4f}")

    return {
        "model_name": model_name,
        "load_time": load_time,
        "dimension": model.get_sentence_embedding_dimension(),
        "encode_time_per_doc": encode_time / len(test_texts),
        "best_similarity": max(similarities),
        "worst_similarity": min(similarities),
        "discrimination": max(similarities) - min(similarities)
    }


def compare_models():
    """å¯¹æ¯”å¤šä¸ªæ¨¡å‹"""
    models = [
        "BAAI/bge-small-zh-v1.5",  # å½“å‰ä½¿ç”¨
        "BAAI/bge-base-zh-v1.5",   # æ¨èå‡çº§
        # "BAAI/bge-large-zh-v1.5",  # é«˜è´¨é‡ï¼ˆå¦‚éœ€è¦è¯·å–æ¶ˆæ³¨é‡Šï¼‰
    ]

    results = []
    for model_name in models:
        result = test_embedding_model(model_name)
        if result:
            results.append(result)

    # å¯¹æ¯”æ€»ç»“
    if len(results) > 1:
        print(f"\n{'='*70}")
        print("ğŸ“Š æ¨¡å‹å¯¹æ¯”æ€»ç»“")
        print(f"{'='*70}")
        print(f"\n{'æŒ‡æ ‡':<20} {'small':<15} {'base':<15} {'æå‡':<15}")
        print(f"{'-'*70}")

        small = results[0]
        base = results[1] if len(results) > 1 else None

        if base:
            print(f"{'å‘é‡ç»´åº¦':<20} {small['dimension']:<15} {base['dimension']:<15} {'+' + str(base['dimension']-small['dimension']):<15}")
            print(f"{'åŠ è½½æ—¶é—´(ç§’)':<20} {small['load_time']:<15.2f} {base['load_time']:<15.2f} {'+' + f\"{base['load_time']-small['load_time']:.2f}\":<15}")
            print(f"{'ç¼–ç é€Ÿåº¦(ms/doc)':<20} {small['encode_time_per_doc']*1000:<15.1f} {base['encode_time_per_doc']*1000:<15.1f} {'+' + f\"{(base['encode_time_per_doc']-small['encode_time_per_doc'])*1000:.1f}\":<15}")
            print(f"{'æœ€ä½³ç›¸ä¼¼åº¦':<20} {small['best_similarity']:<15.4f} {base['best_similarity']:<15.4f} {'+' + f\"{base['best_similarity']-small['best_similarity']:.4f}\":<15}")
            print(f"{'åŒºåˆ†åº¦':<20} {small['discrimination']:<15.4f} {base['discrimination']:<15.4f} {'+' + f\"{base['discrimination']-small['discrimination']:.4f}\":<15}")
            
            print(f"\nğŸ’¡ ç»“è®º:")
            if base['discrimination'] > small['discrimination']:
                improvement = (base['discrimination'] / small['discrimination'] - 1) * 100
                print(f"   âœ… baseæ¨¡å‹åŒºåˆ†åº¦æå‡ {improvement:.1f}%")
                print(f"   âœ… æ¨èå‡çº§åˆ° bge-base-zh-v1.5")
            print(f"   âš ï¸  åŠ è½½æ—¶é—´å¢åŠ  {base['load_time']-small['load_time']:.2f}ç§’ï¼ˆé¦–æ¬¡åŠ è½½ï¼‰")
            print(f"   âš ï¸  ç¼–ç æ—¶é—´å¢åŠ  {(base['encode_time_per_doc']-small['encode_time_per_doc'])*1000:.1f}ms/doc")


if __name__ == "__main__":
    print("ğŸ”¬ Embeddingæ¨¡å‹æ€§èƒ½æµ‹è¯•")
    print("="*70)
    print("è¯´æ˜: é¦–æ¬¡è¿è¡Œä¼šä¸‹è½½æ¨¡å‹åˆ° ~/.cache/huggingface/")
    print("      smallæ¨¡å‹ ~100MB, baseæ¨¡å‹ ~400MB")
    print("="*70)

    compare_models()

    print(f"\n{'='*70}")
    print("âœ… æµ‹è¯•å®Œæˆ")
    print(f"{'='*70}")

