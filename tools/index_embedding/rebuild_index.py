# -*- coding: utf-8 -*-
"""
é‡å»ºç´¢å¼•è„šæœ¬ï¼ˆå‡çº§embeddingæ¨¡å‹åä½¿ç”¨ï¼‰

âš ï¸ é‡è¦: æ›´æ¢embeddingæ¨¡å‹åå¿…é¡»é‡å»ºç´¢å¼•ï¼
"""
import os
import sys
import time
from pathlib import Path

print("="*70)
print("ğŸ”„ é‡å»ºå‘é‡ç´¢å¼•")
print("="*70)

# ç¡®è®¤æ“ä½œ
print("\nâš ï¸  æ³¨æ„äº‹é¡¹:")
print("  1. é‡å»ºç´¢å¼•ä¼šè¦†ç›–ç°æœ‰ç´¢å¼•æ–‡ä»¶")
print("  2. ç¡®ä¿å·²æ›´æ–° config.py ä¸­çš„ embed_model é…ç½®")
print("  3. é¦–æ¬¡ä½¿ç”¨æ–°æ¨¡å‹ä¼šä¸‹è½½åˆ°æœ¬åœ°ï¼ˆéœ€è¦ç½‘ç»œï¼‰")
print("  4. é‡å»ºæ—¶é—´å–å†³äºæ–‡æ¡£æ•°é‡å’Œæ¨¡å‹å¤§å°")

response = input("\næ˜¯å¦ç»§ç»­é‡å»ºç´¢å¼•ï¼Ÿ[y/N]: ").strip().lower()
if response != 'y':
    print("âŒ å·²å–æ¶ˆ")
    sys.exit(0)

print("\n" + "="*70)
print("å¼€å§‹é‡å»º...")
print("="*70)

start_time = time.time()

# å¯¼å…¥å¹¶æ‰§è¡Œ build_index
try:
    # åˆ‡æ¢åˆ° tools ç›®å½•
    tools_dir = Path(__file__).parent
    os.chdir(tools_dir)

    print("\nğŸ“¦ 1/3 - åŠ è½½é…ç½®å’Œæ¨¡å‹...")
    from sentence_transformers import SentenceTransformer
    import numpy as np
    import faiss
    import json
    import pathlib
    from tqdm import tqdm

    CHUNK_DIR = "../../dataset/chunks"
    INDEX_DIR = "../../dataset/index"
    os.makedirs(INDEX_DIR, exist_ok=True)

    # ä»é…ç½®è¯»å–æ¨¡å‹å
    sys.path.insert(0, str(tools_dir.parent))
    from app.core.config import Settings
    settings = Settings()
    model_name = settings.embed_model

    print(f"   ä½¿ç”¨æ¨¡å‹: {model_name}")
    model = SentenceTransformer(model_name)
    dim = model.get_sentence_embedding_dimension()
    print(f"   å‘é‡ç»´åº¦: {dim}")

    print("\nğŸ“ 2/3 - ç¼–ç æ–‡æ¡£åˆ†å—...")
    embeddings, metas = [], []
    chunk_files = list(pathlib.Path(CHUNK_DIR).glob("*.jsonl"))
    print(f"   å‘ç° {len(chunk_files)} ä¸ªåˆ†å—æ–‡ä»¶")

    total_chunks = 0
    for file in tqdm(chunk_files, desc="   ç¼–ç è¿›åº¦"):
        with open(file, encoding="utf-8") as f:
            for line in f:
                d = json.loads(line)
                # ç»„åˆæ ‡é¢˜å’Œæ­£æ–‡
                txt = " ".join(d["titles"]) + " " + d["text"]
                emb = model.encode(txt, normalize_embeddings=True)
                embeddings.append(emb)
                metas.append(d)
                total_chunks += 1

    print(f"   âœ… å·²ç¼–ç  {total_chunks} ä¸ªæ–‡æ¡£å—")

    print("\nğŸ” 3/3 - æ„å»ºFAISSç´¢å¼•...")
    X = np.array(embeddings, dtype="float32")
    print(f"   å‘é‡çŸ©é˜µå½¢çŠ¶: {X.shape}")

    # ä½¿ç”¨å†…ç§¯ç´¢å¼•ï¼ˆä½™å¼¦ç›¸ä¼¼åº¦ï¼‰
    index = faiss.IndexFlatIP(X.shape[1])
    index.add(X)

    index_path = f"{INDEX_DIR}/faiss.index"
    faiss.write_index(index, index_path)
    print(f"   âœ… FAISSç´¢å¼•å·²ä¿å­˜: {index_path}")

    meta_path = f"{INDEX_DIR}/meta.jsonl"
    with open(meta_path, "w", encoding="utf-8") as f:
        for m in metas:
            f.write(json.dumps(m, ensure_ascii=False) + "\n")
    print(f"   âœ… å…ƒæ•°æ®å·²ä¿å­˜: {meta_path}")

    elapsed = time.time() - start_time
    print("\n" + "="*70)
    print("âœ… ç´¢å¼•é‡å»ºå®Œæˆ!")
    print("="*70)
    print(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    print(f"   æ–‡æ¡£åˆ†å—æ•°: {total_chunks}")
    print(f"   å‘é‡ç»´åº¦: {dim}")
    print(f"   ç´¢å¼•å¤§å°: {os.path.getsize(index_path) / 1024 / 1024:.1f} MB")
    print(f"   è€—æ—¶: {elapsed:.2f} ç§’")
    print(f"   å¹³å‡é€Ÿåº¦: {total_chunks/elapsed:.1f} å—/ç§’")

    print(f"\nğŸ’¡ ä¸‹ä¸€æ­¥:")
    print(f"   1. è¿è¡Œ python ../test_startup.py æµ‹è¯•æœåŠ¡")
    print(f"   2. è¿è¡Œ uvicorn app.main:app --reload å¯åŠ¨æœåŠ¡")

except Exception as e:
    print(f"\nâŒ é‡å»ºå¤±è´¥: {e}")
    import traceback
    traceback.print_exc()
    sys.exit(1)

