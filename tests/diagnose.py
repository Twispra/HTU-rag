# -*- coding: utf-8 -*-
"""
ç³»ç»Ÿè¯Šæ–­è„šæœ¬ - æ£€æŸ¥æ‰€æœ‰é…ç½®å’ŒæœåŠ¡çŠ¶æ€
"""
import os
import sys
from pathlib import Path

print("="*70)
print("ğŸ” RAGç³»ç»Ÿè¯Šæ–­")
print("="*70)

# 1. æ£€æŸ¥ç¯å¢ƒå˜é‡ï¼ˆAPI Keysï¼‰
print("\n1ï¸âƒ£  æ£€æŸ¥APIå¯†é’¥é…ç½®...")
env_file = Path("../.env")
if env_file.exists():
    print(f"   âœ… .env æ–‡ä»¶å­˜åœ¨")
    with open(env_file, encoding='utf-8') as f:
        content = f.read()
        keys_to_check = [
            "DEEPSEEK_API_KEY",
            "OPENAI_API_KEY",
            "DASHSCOPE_API_KEY",
            "ZHIPU_API_KEY"
        ]
        found_keys = []
        for key in keys_to_check:
            if key in content and not content.split(key)[1].split('\n')[0].strip('= ').startswith('#'):
                found_keys.append(key)
                # æ£€æŸ¥æ˜¯å¦ä¸ºç©º
                value = os.getenv(key)
                if value and value.strip():
                    print(f"   âœ… {key}: å·²é…ç½®")
                else:
                    print(f"   âš ï¸  {key}: å­˜åœ¨ä½†ä¸ºç©º")
            else:
                env_value = os.getenv(key)
                if env_value:
                    print(f"   âœ… {key}: é€šè¿‡ç¯å¢ƒå˜é‡é…ç½®")
                else:
                    print(f"   âšª {key}: æœªé…ç½®")

        if not found_keys and not any(os.getenv(k) for k in keys_to_check):
            print(f"   âš ï¸  æœªæ‰¾åˆ°ä»»ä½•APIå¯†é’¥é…ç½®")
else:
    print(f"   âš ï¸  .env æ–‡ä»¶ä¸å­˜åœ¨")
    print(f"   ğŸ’¡ è¯·åˆ›å»º.envæ–‡ä»¶å¹¶é…ç½®APIå¯†é’¥")

# 2. æ£€æŸ¥é…ç½®
print("\n2ï¸âƒ£  æ£€æŸ¥åº”ç”¨é…ç½®...")
try:
    sys.path.insert(0, '..')
    from app.core.config import Settings
    settings = Settings()
    print(f"   âœ… é…ç½®åŠ è½½æˆåŠŸ")
    print(f"   ğŸ“¦ LLMæä¾›å•†: {settings.llm_provider}")
    print(f"   ğŸ¤– LLMæ¨¡å‹: {settings.llm_model}")
    print(f"   ğŸ“Š Embeddingæ¨¡å‹: {settings.embed_model}")
    print(f"   ğŸ”„ Rerankæ¨¡å‹: {settings.rerank_model or 'æœªå¯ç”¨'}")

    # æ£€æŸ¥å¯¹åº”çš„API keyæ˜¯å¦é…ç½®
    key_map = {
        "deepseek": "DEEPSEEK_API_KEY",
        "openai": "OPENAI_API_KEY",
        "qwen": "DASHSCOPE_API_KEY",
        "zhipu": "ZHIPU_API_KEY"
    }
    required_key = key_map.get(settings.llm_provider.lower())
    if required_key:
        key_value = os.getenv(required_key)
        if key_value and key_value.strip():
            print(f"   âœ… {required_key} å·²é…ç½®")
        else:
            print(f"   âŒ {required_key} æœªé…ç½®æˆ–ä¸ºç©ºï¼")
            print(f"   ğŸ’¡ è¯·åœ¨.envæ–‡ä»¶ä¸­æ·»åŠ : {required_key}=your_api_key_here")

except Exception as e:
    print(f"   âŒ é…ç½®åŠ è½½å¤±è´¥: {e}")
    sys.exit(1)

# 3. æ£€æŸ¥ç´¢å¼•æ–‡ä»¶
print("\n3ï¸âƒ£  æ£€æŸ¥å‘é‡ç´¢å¼•...")
index_dir = Path(settings.index_dir)
index_file = index_dir / "faiss.index"
meta_file = index_dir / "meta.jsonl"

if index_file.exists() and meta_file.exists():
    print(f"   âœ… ç´¢å¼•æ–‡ä»¶å­˜åœ¨")

    try:
        import faiss
        index = faiss.read_index(str(index_file))
        print(f"   ğŸ“Š å‘é‡ç»´åº¦: {index.d}")
        print(f"   ğŸ“ å‘é‡æ•°é‡: {index.ntotal}")

        # æ£€æŸ¥ç»´åº¦æ˜¯å¦åŒ¹é…
        expected_dim = {
            "small": 512,
            "base": 768,
            "large": 1024
        }
        model_type = None
        for key in expected_dim:
            if key in settings.embed_model.lower():
                model_type = key
                break

        if model_type and expected_dim[model_type] == index.d:
            print(f"   âœ… ç´¢å¼•ç»´åº¦ä¸æ¨¡å‹åŒ¹é… ({model_type}-{index.d}ç»´)")
        elif model_type:
            print(f"   âŒ ç´¢å¼•ç»´åº¦({index.d})ä¸æ¨¡å‹({model_type}-{expected_dim[model_type]}ç»´)ä¸åŒ¹é…ï¼")
            print(f"   ğŸ’¡ éœ€è¦é‡å»ºç´¢å¼•: python tools/rebuild_index.py")

    except Exception as e:
        print(f"   âš ï¸  ç´¢å¼•æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
else:
    print(f"   âŒ ç´¢å¼•æ–‡ä»¶ä¸å­˜åœ¨")
    print(f"   ğŸ’¡ è¯·è¿è¡Œ: python tools/rebuild_index.py")

# 4. æ£€æŸ¥æ–‡æ¡£æ•°æ®
print("\n4ï¸âƒ£  æ£€æŸ¥æ–‡æ¡£æ•°æ®...")
chunk_dir = Path("../dataset/chunks")
if chunk_dir.exists():
    chunk_files = list(chunk_dir.glob("*.jsonl"))
    print(f"   âœ… åˆ†å—ç›®å½•å­˜åœ¨")
    print(f"   ğŸ“¦ åˆ†å—æ–‡ä»¶æ•°: {len(chunk_files)}")

    if len(chunk_files) == 0:
        print(f"   âš ï¸  æ²¡æœ‰åˆ†å—æ–‡ä»¶")
        print(f"   ğŸ’¡ è¯·è¿è¡Œ: cd tools; python chunking.py")
else:
    print(f"   âŒ åˆ†å—ç›®å½•ä¸å­˜åœ¨")

# 5. æµ‹è¯•LLMè¿æ¥
print("\n5ï¸âƒ£  æµ‹è¯•LLMè¿æ¥...")
try:
    from app.models.llm import make_llm

    required_key = key_map.get(settings.llm_provider.lower())
    key_value = os.getenv(required_key)

    if not key_value or not key_value.strip():
        print(f"   âš ï¸  è·³è¿‡æµ‹è¯•ï¼ˆAPIå¯†é’¥æœªé…ç½®ï¼‰")
    else:
        print(f"   ğŸ”„ æ­£åœ¨æµ‹è¯•{settings.llm_provider}è¿æ¥...")
        llm = make_llm(
            settings.llm_provider,
            model=settings.llm_model,
            temperature=settings.llm_temperature,
            max_tokens=100
        )

        test_messages = [
            {"role": "user", "content": "ä½ å¥½ï¼Œè¯·å›å¤'æµ‹è¯•æˆåŠŸ'"}
        ]

        response = llm.chat(test_messages)
        print(f"   âœ… LLMè¿æ¥æˆåŠŸ")
        print(f"   ğŸ’¬ æµ‹è¯•å›å¤: {response[:50]}...")

except Exception as e:
    print(f"   âŒ LLMè¿æ¥å¤±è´¥: {e}")
    print(f"   ğŸ’¡ è¯·æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æ­£ç¡®")

# 6. æµ‹è¯•æ£€ç´¢æœåŠ¡
print("\n6ï¸âƒ£  æµ‹è¯•æ£€ç´¢æœåŠ¡...")
try:
    if index_file.exists():
        from app.services.retrieval import RetrievalService

        print(f"   ğŸ”„ æ­£åœ¨åˆå§‹åŒ–æ£€ç´¢æœåŠ¡...")
        print(f"   ğŸ“¦ ä½¿ç”¨æ¨¡å‹: {settings.embed_model}")
        retrieval = RetrievalService(
            index_dir=str(index_dir),
            embed_model_name=settings.embed_model,  # ä½¿ç”¨é…ç½®ä¸­çš„æ¨¡å‹
            rerank_model_name=settings.rerank_model,
            topk_faiss=settings.topk_faiss,
            topk_final=settings.topk_final
        )

        print(f"   ğŸ”„ æ­£åœ¨æµ‹è¯•æ£€ç´¢...")
        results = retrieval.retrieve("æµ‹è¯•æŸ¥è¯¢")
        print(f"   âœ… æ£€ç´¢æœåŠ¡æ­£å¸¸")
        print(f"   ğŸ“Š è¿”å›ç»“æœæ•°: {len(results)}")
    else:
        print(f"   âš ï¸  è·³è¿‡æµ‹è¯•ï¼ˆç´¢å¼•ä¸å­˜åœ¨ï¼‰")

except Exception as e:
    print(f"   âŒ æ£€ç´¢æœåŠ¡å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()

# æ€»ç»“
print("\n" + "="*70)
print("ğŸ“‹ è¯Šæ–­æ€»ç»“")
print("="*70)

issues = []
if not env_file.exists() or not any(os.getenv(k) for k in keys_to_check):
    issues.append("âš ï¸  APIå¯†é’¥æœªé…ç½®")

if not index_file.exists():
    issues.append("âš ï¸  å‘é‡ç´¢å¼•æœªæ„å»º")

if len(chunk_files) == 0 if chunk_dir.exists() else True:
    issues.append("âš ï¸  æ–‡æ¡£åˆ†å—æœªç”Ÿæˆ")

if issues:
    print("\nå‘ç°ä»¥ä¸‹é—®é¢˜:")
    for issue in issues:
        print(f"  {issue}")

    print("\nğŸ’¡ è§£å†³æ–¹æ¡ˆ:")
    if "APIå¯†é’¥" in str(issues):
        print("  1. åˆ›å»ºæˆ–ç¼–è¾‘ .env æ–‡ä»¶")
        print("  2. æ·»åŠ APIå¯†é’¥ï¼Œä¾‹å¦‚: DEEPSEEK_API_KEY=sk-xxx")
    if "æ–‡æ¡£åˆ†å—" in str(issues):
        print("  3. è¿è¡Œ: cd tools; python chunking.py")
    if "å‘é‡ç´¢å¼•" in str(issues):
        print("  4. è¿è¡Œ: python tools/rebuild_index.py")
else:
    print("\nâœ… æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼ç³»ç»Ÿå¯ä»¥æ­£å¸¸è¿è¡Œã€‚")
    print("\nğŸš€ å¯åŠ¨å‘½ä»¤:")
    print("   uvicorn app.main:app --reload --port 8000")

print("\n" + "="*70)

